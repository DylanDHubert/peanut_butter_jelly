# ğŸ¥œğŸ§ˆğŸ‡ PB&J Pipeline
## Parse, Better, JSON - The Ultimate RAG Document Processing Pipeline

The **PB&J Pipeline** is a three-stage document processing system that transforms PDFs into clean, structured JSON optimized for RAG (Retrieval-Augmented Generation) applications.

### ğŸ¯ **What is PB&J?**
- **ğŸ¥œ Peanut (Parse)**: Extract raw content from PDFs using LlamaParse
- **ğŸ§ˆ Butter (Better)**: Enhance markdown structure and readability with AI
- **ğŸ‡ Jelly (JSON)**: Convert to clean, searchable JSON for RAG systems

---

## ğŸ—ï¸ **Pipeline Architecture**

### **Stage 1: ğŸ¥œ Peanut (Parse)**
- **Tool**: LlamaParse Premium API
- **Input**: PDF documents
- **Output**: Raw markdown with tables and technical content
- **Features**: 
  - Premium mode for complex technical documents
  - Visual marker detection (checkboxes, bullets â†’ TRUE/FALSE)
  - Table structure preservation
  - OCR for faint marks and symbols

### **Stage 2: ğŸ§ˆ Butter (Better)**
- **Tool**: OpenAI GPT-4
- **Input**: Raw markdown from Peanut stage
- **Output**: Enhanced markdown with improved structure
- **Features**:
  - Better table headers with units (e.g., "Diameter" â†’ "Diameter (mm)")
  - Integrated footnotes and legends
  - Expanded abbreviations
  - Context-aware descriptions
  - Perfect data preservation (no data loss)

### **Stage 3: ğŸ‡ Jelly (JSON)**
- **Tool**: OpenAI GPT-4
- **Input**: Enhanced markdown from Butter stage
- **Output**: Structured JSON optimized for RAG
- **Features**:
  - Searchable keywords and summaries
  - Complete table extraction
  - Technical metadata
  - Data type classification
  - RAG-optimized structure

---

## ğŸ“ **Organized Output Structure**

Each document gets its own organized folder:

```
document_folder/
â”œâ”€â”€ ğŸ¥œ Peanut Stage
â”‚   â”œâ”€â”€ original.pdf                    # Original PDF file
â”‚   â””â”€â”€ 01_parsed_markdown/             # Raw LlamaParse output
â”‚       â”œâ”€â”€ page_1.md
â”‚       â””â”€â”€ page_2.md
â”œâ”€â”€ ğŸ§ˆ Butter Stage  
â”‚   â””â”€â”€ 02_enhanced_markdown/           # Enhanced structure
â”‚       â”œâ”€â”€ page_1.md (saved immediately)
â”‚       â””â”€â”€ page_2.md
â”œâ”€â”€ ğŸ‡ Jelly Stage
â”‚   â””â”€â”€ 03_cleaned_json/               # Individual page JSONs
â”‚       â”œâ”€â”€ page_1.json (saved immediately)
â”‚       â””â”€â”€ page_2.json
â””â”€â”€ ğŸ¥œğŸ§ˆğŸ‡ Final PB&J Output
    â”œâ”€â”€ final_output.json              # Combined JSON
    â”œâ”€â”€ document_metadata.json         # Pipeline tracking
    â””â”€â”€ pipeline_summary.json          # Complete summary
```

---

## ğŸš€ **Quick Start**

### **Prerequisites**
```bash
pip install -r requirements.txt
```

**Required API Keys:**
- `LLAMA_CLOUD_API_KEY` - For LlamaParse (Peanut stage)
- `OPENAI_API_KEY` - For enhancement and cleaning (Butter & Jelly stages)

### **Complete PB&J Pipeline**
```python
# Complete pipeline in one line
from pbj import Sandwich

sandwich = Sandwich(use_premium=True, openai_model="gpt-4")
result = sandwich.make("document.pdf")
print(f"Results saved to: {result['folder_structure']['main_folder']}")
```

```bash
# Or via command line
python3 -m pbj.sandwich document.pdf --premium --model gpt-4
```

### **Stage-by-Stage Execution**

#### **ğŸ¥œ Peanut Only (Parse)**
```python
from pbj import Peanut

peanut = Peanut(use_premium=True)
parsed_docs = peanut.pdf2md("document.pdf")
result = peanut.save_parsed_documents(parsed_docs, source_pdf_path="document.pdf")
```

#### **ğŸ§ˆ Butter Only (Better)**
```python
from pbj import Butter

butter = Butter(model="gpt-4")
enhanced_docs = butter.enhance_document_folder("data/document_folder")
```

#### **ğŸ‡ Jelly Only (JSON)**
```python
from pbj import Jelly

jelly = Jelly(model="gpt-4")
processed_pages = jelly.process_document_folder("data/document_folder")
```

### **Individual Method Usage**
```python
from pbj import Peanut, Butter, Jelly

# Stage 1: Parse PDF to markdown
peanut = Peanut(use_premium=True)
parsed_docs = peanut.pdf2md("document.pdf")

# Stage 2: Enhance markdown structure  
butter = Butter(model="gpt-4")
enhanced_doc = butter.md2md(parsed_docs[0].content, "document.md")

# Stage 3: Extract structured JSON
jelly = Jelly(model="gpt-4")
json_result = jelly.md2json(enhanced_doc.enhanced_content, "document.md")
```

---

## ğŸ› ï¸ **Configuration**

### **Peanut (Parse) Configuration**
- **Files**: `config/pdf_system_prompt.txt`, `config/pdf_user_prompt.txt`
- **Settings**: Premium mode, OCR enabled, HTML tables, visual marker detection

### **Butter (Better) Configuration**
- **File**: `config/markdown_enhancement_prompt.txt`
- **Focus**: Structure improvement while preserving all data

### **Jelly (JSON) Configuration**
- **File**: `config/data_cleaning_prompt.txt`
- **Focus**: RAG optimization and searchable JSON structure

---

## ğŸ“Š **Pipeline Features**

### **ğŸ”„ Immediate Saves**
- **Peanut**: Saves after complete PDF parsing
- **Butter**: Saves after each page enhancement
- **Jelly**: Saves after each page processing + final combined output

### **ğŸ“ˆ Data Integrity**
- âœ… **Zero data loss**: Every table row preserved exactly
- âœ… **Numerical fidelity**: All measurements and values identical
- âœ… **Boolean integrity**: TRUE/FALSE values from visual markers
- âœ… **Complete tracking**: Metadata tracks every stage

### **ğŸ¯ RAG Optimization**
- Searchable keywords and summaries
- Technical terminology extraction
- Table structure with metadata
- Data type classification
- Measurement units standardization

---

## ğŸ§ª **Testing**

### **Test Complete Pipeline**
```bash
python3 test_new_structure.py
```

### **Continue from Specific Stage**
```bash
# Continue from Butter stage (if Peanut already completed)
python3 continue_pipeline.py data/document_folder
```

---

## ğŸ“ **File Structure**

```
ğŸ¥œğŸ§ˆğŸ‡ PB&J Pipeline/
â”œâ”€â”€ src/pbj/                       # Main PB&J package
â”‚   â”œâ”€â”€ __init__.py               # Package imports
â”‚   â”œâ”€â”€ ğŸ¥œ peanut.py              # Parse stage (LlamaParse)
â”‚   â”œâ”€â”€ ğŸ§ˆ butter.py              # Better stage (OpenAI)
â”‚   â”œâ”€â”€ ğŸ‡ jelly.py               # JSON stage (OpenAI)
â”‚   â”œâ”€â”€ ğŸ¥ª sandwich.py            # Complete pipeline
â”‚   â””â”€â”€ pantry/                   # Configuration pantry
â”‚       â”œâ”€â”€ pea.txt               # Peanut system prompt
â”‚       â”œâ”€â”€ nut.txt               # Peanut user prompt  
â”‚       â”œâ”€â”€ butter.txt            # Butter enhancement prompt
â”‚       â””â”€â”€ jelly.txt             # Jelly extraction prompt
â”œâ”€â”€ ğŸ“‹ Documentation
â”‚   â”œâ”€â”€ README.md                 # This file
â”‚   â””â”€â”€ requirements.txt          # Dependencies
â””â”€â”€ ğŸ§ª Testing
    â””â”€â”€ test_pbj.py               # Package structure test
```

### **Package Import Structure**
```python
# Main classes (fun names for humans)
from pbj import Peanut, Butter, Jelly, Sandwich

# Simple method names (for coding agents)
peanut.pdf2md()    # PDF â†’ Markdown
butter.md2md()     # Markdown â†’ Enhanced Markdown  
jelly.md2json()    # Markdown â†’ JSON
sandwich.make()    # Complete pipeline

# Fun aliases (for the adventurous)
from pbj import Parse, Better, JSON, Pipeline
```

---

## ğŸ‰ **Why PB&J?**

1. **ğŸ¥œ Peanut (Parse)**: The foundation - extracts raw content like peanuts from shells
2. **ğŸ§ˆ Butter (Better)**: The enhancement - makes everything smoother and better
3. **ğŸ‡ Jelly (JSON)**: The sweetness - creates the final delicious, structured output

Together they make the perfect **PB&J sandwich** - a complete, satisfying solution for document processing! ğŸ¥ª

---

## ğŸ“ **Support**

The PB&J Pipeline transforms technical PDFs into RAG-ready JSON with:
- **6 tables extracted** from test document
- **19 unique keywords** generated
- **4 pages processed** in organized structure
- **Perfect data preservation** throughout all stages

**Made with â¤ï¸ and a love for good sandwiches** ğŸ¥œğŸ§ˆğŸ‡
